{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "40912a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, Concatenate,concatenate, Dense, Flatten, Reshape\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52252086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(filtered_signal_data_for_label_2, filtered_signal_data_for_label_3, filtered_signal_data_for_label_4):\n",
    "    \n",
    "    return (\n",
    "        np.array([filtered_signal_data_for_label_2[i:i+segment_size] for i in range(0,len(filtered_signal_data_for_label_2) - segment_size + 1,overlap)]),\n",
    "        np.array([filtered_signal_data_for_label_3[i:i+segment_size] for i in range(0,len(filtered_signal_data_for_label_3) - segment_size + 1,overlap)]),\n",
    "        np.array([filtered_signal_data_for_label_4[i:i+segment_size] for i in range(0,len(filtered_signal_data_for_label_4) - segment_size + 1,overlap)]) \n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "162efdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject : ======= >>  S4\n",
      "(2540, 1) (2540, 1)\n",
      "(2000, 1) (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "frequency=0\n",
    "train_duration =40\n",
    "overlap=0\n",
    "# subject=\"S11\"\n",
    "subject = \"S4\"\n",
    "signal= \"TEMP\"\n",
    "root = \"../Wesad/Dataset/WESAD/untitled folder/\"\n",
    "path = root+subject+\".pkl\"\n",
    "\n",
    "for subject in ['S4']:\n",
    "    print(\"Subject : ======= >> \", subject)\n",
    "    if signal==\"ACC\":\n",
    "        frequency= 32\n",
    "    elif signal==\"BVP\":\n",
    "        frequency= 64\n",
    "    else:\n",
    "        frequency= 4\n",
    "\n",
    "    segment_size = train_duration*frequency\n",
    "    if frequency==1:\n",
    "        overlap=frequency\n",
    "    else:\n",
    "        overlap = int(0.5*frequency)\n",
    "\n",
    "    with open(path, 'rb') as file:\n",
    "        whole_signal = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    \n",
    "    # data= whole_signal['signal']['wrist'][signal]\n",
    "    data_eda= whole_signal['signal']['wrist']['EDA']\n",
    "    data_temp= whole_signal['signal']['wrist']['TEMP']\n",
    "    \n",
    "    \n",
    "    labels_chest = whole_signal[\"label\"]\n",
    "    \n",
    "    labels_wrist = []\n",
    "    for i in range(0, len(labels_chest), 700):\n",
    "        for _ in range(frequency):\n",
    "            labels_wrist.append(labels_chest[i])\n",
    "            \n",
    "    labels_wrist = np.array(labels_wrist)\n",
    "    \n",
    "#     labels_wrist = whole_signal[\"label\"]\n",
    "    \n",
    "    \n",
    "    filtered_indices_label_0 = np.where(labels_wrist == 0)  \n",
    "    filtered_indices_label_0= filtered_indices_label_0[0]\n",
    "    \n",
    "    filtered_indices_label_1 = np.where(labels_wrist == 1)  \n",
    "    filtered_indices_label_1= filtered_indices_label_1[0]\n",
    "    \n",
    "    \n",
    "    filtered_indices_label_2 = np.where(labels_wrist == 2)  # 2= stress\n",
    "    filtered_indices_label_2= filtered_indices_label_2[0]\n",
    "    \n",
    "    \n",
    "    filtered_indices_label_3 = np.where(labels_wrist == 3) # 3 = amusement\n",
    "    filtered_indices_label_3= filtered_indices_label_3[0]\n",
    "\n",
    "    \n",
    "    filtered_indices_label_4 = np.where(labels_wrist == 4) # 4 =\n",
    "    filtered_indices_label_4 = filtered_indices_label_4[0]\n",
    "    \n",
    "    filtered_indices_label_5 = np.where(labels_wrist == 5)  \n",
    "    filtered_indices_label_5= filtered_indices_label_5[0]\n",
    "    \n",
    "    filtered_indices_label_6 = np.where(labels_wrist == 6) \n",
    "    filtered_indices_label_6= filtered_indices_label_6[0]\n",
    "    \n",
    "    filtered_indices_label_7 = np.where(labels_wrist == 7)  \n",
    "    filtered_indices_label_7= filtered_indices_label_7[0]\n",
    "    \n",
    "    \n",
    "    eda_data_for_label_0 = data_eda[filtered_indices_label_0]\n",
    "    eda_data_for_label_1 = data_eda[filtered_indices_label_1]\n",
    "    eda_data_for_label_2 = data_eda[filtered_indices_label_2]\n",
    "    eda_data_for_label_3 = data_eda[filtered_indices_label_3]\n",
    "    eda_data_for_label_4 = data_eda[filtered_indices_label_4]\n",
    "    eda_data_for_label_5 = data_eda[filtered_indices_label_5]\n",
    "    eda_data_for_label_6 = data_eda[filtered_indices_label_6]\n",
    "    eda_data_for_label_7 = data_eda[filtered_indices_label_7]\n",
    "    \n",
    "    \n",
    "    temp_data_for_label_0 = data_temp[filtered_indices_label_0]\n",
    "    temp_data_for_label_1 = data_temp[filtered_indices_label_1]\n",
    "    temp_data_for_label_2 = data_temp[filtered_indices_label_2]\n",
    "    temp_data_for_label_3 = data_temp[filtered_indices_label_3]\n",
    "    temp_data_for_label_4 = data_temp[filtered_indices_label_4]\n",
    "    temp_data_for_label_5 = data_temp[filtered_indices_label_5]\n",
    "    temp_data_for_label_6 = data_temp[filtered_indices_label_6]\n",
    "    temp_data_for_label_7 = data_temp[filtered_indices_label_7]\n",
    "    \n",
    "    print(eda_data_for_label_2.shape,temp_data_for_label_2.shape)\n",
    "    \n",
    "    \n",
    "    eda_data_for_label_2 = eda_data_for_label_2[:-540]\n",
    "    temp_data_for_label_2 = temp_data_for_label_2[:-540]\n",
    "    \n",
    "    print(eda_data_for_label_2.shape,temp_data_for_label_2.shape)\n",
    "    \n",
    "#     exclude_eda_data_for_test_from_label_2 = eda_data_for_label_2[:-200]\n",
    "#     exclude_temp_data_for_test_from_label_2 = temp_data_for_label_2[:-200]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    data_eda_label_0 = np.array([eda_data_for_label_0[i:i + segment_size] for i in range(0, len(eda_data_for_label_0) - segment_size + 1, overlap)])\n",
    "    data_eda_label_1 = np.array([eda_data_for_label_1[i:i + segment_size] for i in range(0, len(eda_data_for_label_1) - segment_size + 1, overlap)])\n",
    "    data_eda_label_2 = np.array([eda_data_for_label_2[i:i + segment_size] for i in range(0, len(eda_data_for_label_2) - segment_size + 1, overlap)])\n",
    "    data_eda_label_3 = np.array([eda_data_for_label_3[i:i + segment_size] for i in range(0, len(eda_data_for_label_3) - segment_size + 1, overlap)])\n",
    "    data_eda_label_4 = np.array([eda_data_for_label_4[i:i + segment_size] for i in range(0, len(eda_data_for_label_4) - segment_size + 1, overlap)])\n",
    "    data_eda_label_5 = np.array([eda_data_for_label_5[i:i + segment_size] for i in range(0, len(eda_data_for_label_5) - segment_size + 1, overlap)])\n",
    "    data_eda_label_6 = np.array([eda_data_for_label_6[i:i + segment_size] for i in range(0, len(eda_data_for_label_6) - segment_size + 1, overlap)])\n",
    "    data_eda_label_7 = np.array([eda_data_for_label_7[i:i + segment_size] for i in range(0, len(eda_data_for_label_7) - segment_size + 1, overlap)])\n",
    "\n",
    "    data_temp_label_0 = np.array([temp_data_for_label_0[i:i + segment_size] for i in range(0, len(temp_data_for_label_0) - segment_size + 1, overlap)])\n",
    "    data_temp_label_1 = np.array([temp_data_for_label_1[i:i + segment_size] for i in range(0, len(temp_data_for_label_1) - segment_size + 1, overlap)])\n",
    "    data_temp_label_2 = np.array([temp_data_for_label_2[i:i + segment_size] for i in range(0, len(temp_data_for_label_2) - segment_size + 1, overlap)])\n",
    "    data_temp_label_3 = np.array([temp_data_for_label_3[i:i + segment_size] for i in range(0, len(temp_data_for_label_3) - segment_size + 1, overlap)])\n",
    "    data_temp_label_4 = np.array([temp_data_for_label_4[i:i + segment_size] for i in range(0, len(temp_data_for_label_4) - segment_size + 1, overlap)])\n",
    "    data_temp_label_5 = np.array([temp_data_for_label_5[i:i + segment_size] for i in range(0, len(temp_data_for_label_5) - segment_size + 1, overlap)])\n",
    "    data_temp_label_6 = np.array([temp_data_for_label_6[i:i + segment_size] for i in range(0, len(temp_data_for_label_6) - segment_size + 1, overlap)])\n",
    "    data_temp_label_7 = np.array([temp_data_for_label_7[i:i + segment_size] for i in range(0, len(temp_data_for_label_7) - segment_size + 1, overlap)])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    data_eda= np.concatenate((data_eda_label_0,data_eda_label_1,data_eda_label_2,data_eda_label_3,\n",
    "                              data_eda_label_4,data_eda_label_5,data_eda_label_6),axis=0)\n",
    "    \n",
    "    data_temp= np.concatenate((data_temp_label_0,data_temp_label_1,data_temp_label_2,data_temp_label_3,\n",
    "                              data_temp_label_4,data_temp_label_5,data_temp_label_6),axis=0)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f483b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in ['S4']:\n",
    "    print(\"Subject : ======= >> \", subject)\n",
    "    if signal==\"ACC\":\n",
    "        frequency= 32\n",
    "    elif signal==\"BVP\":\n",
    "        frequency= 64\n",
    "    else:\n",
    "        frequency= 4\n",
    "\n",
    "    segment_size = train_duration*frequency\n",
    "    if frequency==1:\n",
    "        overlap=frequency\n",
    "    else:\n",
    "        overlap = int(0.5*frequency)\n",
    "\n",
    "    with open(path, 'rb') as file:\n",
    "        whole_signal = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    \n",
    "    # data= whole_signal['signal']['wrist'][signal]\n",
    "    data_eda= whole_signal['signal']['wrist']['EDA'].flatten()\n",
    "    data_temp= whole_signal['signal']['wrist']['TEMP'].flatten()\n",
    "    \n",
    "    \n",
    "    labels_chest = whole_signal[\"label\"]\n",
    "    \n",
    "    labels_wrist = []\n",
    "    for i in range(0, len(labels_chest), 700):\n",
    "        for _ in range(frequency):\n",
    "            labels_wrist.append(labels_chest[i])\n",
    "            \n",
    "    labels_wrist = np.array(labels_wrist)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f0606b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25692, 2), (25692, 2))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"eda.csv\").shape,pd.read_csv(\"temp.csv\").shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fbd86be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency=4\n",
    "train_duration =10\n",
    "\n",
    "\n",
    "segment_size = train_duration*frequency\n",
    "\n",
    "data_eda=pd.read_csv(\"train_eda.csv\",usecols=[0])\n",
    "data_eda = data_eda[\"Signal\"].values\n",
    "data_eda = np.array([[item] for item in data_eda])\n",
    "\n",
    "data_temp= pd.read_csv(\"train_temp.csv\",usecols=[0])\n",
    "data_temp = data_temp[\"Signal\"].values\n",
    "data_temp = np.array([[item] for item in data_temp])\n",
    "\n",
    "\n",
    "data_eda = np.array([data_eda[i:i + segment_size] for i in range(0, len(data_eda) - segment_size + 1, overlap)])\n",
    "data_temp = np.array([data_temp[i:i + segment_size] for i in range(0, len(data_temp) - segment_size + 1, overlap)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "597e8302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12472, 40, 1), (12472, 40, 1))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_eda.shape, data_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7826a906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  2560\n",
      "Fc Shape (None, 2560)\n",
      "Fc Shape (None, 5120)\n",
      "New Shape, : (40, 128)\n",
      "Decoder\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class RandomMaskingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, masking_rate=0.2, **kwargs):\n",
    "        super(RandomMaskingLayer, self).__init__(**kwargs)\n",
    "        self.masking_rate = masking_rate\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            mask = tf.random.uniform(shape=tf.shape(inputs)) > self.masking_rate\n",
    "            return inputs * tf.cast(mask, tf.float32)\n",
    "        return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(RandomMaskingLayer, self).get_config()\n",
    "        config.update({\"masking_rate\": self.masking_rate})\n",
    "        return config\n",
    "\n",
    "\n",
    "def create_masked_multimodal_autoencoder(time_steps):\n",
    "    # Input layers for each modality\n",
    "    input_eda = Input(shape=(time_steps, 1), name='input_eda')\n",
    "    input_temp = Input(shape=(time_steps, 1), name='input_temp')\n",
    "\n",
    "    # Masking layers\n",
    "    masked_eda = RandomMaskingLayer(masking_rate=0.2)(input_eda)\n",
    "    masked_temp = RandomMaskingLayer(masking_rate=0.2)(input_temp)\n",
    "\n",
    "    # First branch - EDA\n",
    "    x_eda = Conv1D(32, 3, activation='relu', padding='same')(masked_eda)\n",
    "    x_eda = MaxPooling1D(2, padding='same')(x_eda)\n",
    "    x_eda = Conv1D(64, 3, activation='relu', padding='same')(x_eda)\n",
    "    x_eda = MaxPooling1D(2, padding='same')(x_eda)\n",
    "    encoded_eda = Conv1D(128, 3, activation='relu', padding='same')(x_eda)\n",
    "#     flatten_eda = Flatten()(encoded_eda)\n",
    "\n",
    "    # Second branch - ECG\n",
    "    x_temp = Conv1D(32, 3, activation='relu', padding='same')(masked_temp)\n",
    "    x_temp = MaxPooling1D(2, padding='same')(x_temp)\n",
    "    x_temp = Conv1D(64, 3, activation='relu', padding='same')(x_temp)\n",
    "    x_temp = MaxPooling1D(2, padding='same')(x_temp)\n",
    "    encoded_temp = Conv1D(128, 3, activation='relu', padding='same')(x_temp)\n",
    "#     flatten_eda = Flatten()(encoded_eda)\n",
    "\n",
    "    # Combine branches\n",
    "    combined = concatenate([Flatten()(encoded_eda), Flatten()(encoded_temp)])\n",
    "    \n",
    "    \n",
    "    flattened_size_per_branch = (time_steps // 4) * 128  # Example calculation based on your network structure\n",
    "    total_flattened_size = 2 * flattened_size_per_branch\n",
    "    print(\"Total: \",total_flattened_size)\n",
    "\n",
    "    # Fully connected layers\n",
    "    fc = Dense(total_flattened_size, activation='relu')(combined)\n",
    "    print(\"Fc Shape\", fc.shape)\n",
    "    fc = Dense(time_steps * 128, activation='relu')(fc)  # Adjust the size to match the decoder's input\n",
    "    print(\"Fc Shape\", fc.shape)\n",
    "    reshaped_size = total_flattened_size  # This should be 5120 as per your input shape\n",
    "    new_shape = (time_steps, 128)  # New shape calculated to maintain the same number of elements\n",
    "    print(\"New Shape, :\",new_shape)\n",
    "    # Apply the Reshape layer\n",
    "    reshaped = Reshape(new_shape)(fc)\n",
    "    print(\"Decoder\")\n",
    "    from tensorflow.keras.layers import Lambda\n",
    "    # Decoder\n",
    "    x_combined = Conv1D(128, 3, activation='relu', padding='same')(reshaped)\n",
    "    x_combined = UpSampling1D(2)(x_combined)  # Upsampling\n",
    "    x_combined = Conv1D(64, 3, activation='relu', padding='same')(x_combined)\n",
    "    x_combined = UpSampling1D(2)(x_combined)  # Upsampling\n",
    "\n",
    "    # Crop the output to the correct size\n",
    "    # Assuming you need to crop from 80 to 40\n",
    "    cropped_output = Lambda(lambda x: x[:, :time_steps, :])(x_combined)\n",
    "\n",
    "    decoded = Conv1D(1, 3, activation='sigmoid', padding='same')(cropped_output)\n",
    "\n",
    "\n",
    "    # Define the model\n",
    "    autoencoder = Model(inputs=[input_eda, input_temp], outputs=decoded)\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "# Instantiate the model\n",
    "time_steps = segment_size  # Replace with the actual length of your time series\n",
    "autoencoder = create_masked_multimodal_autoencoder(time_steps)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1c1e67e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 20:54:21.367453: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 31s 193ms/step - loss: 0.2090\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 6s 56ms/step - loss: 0.1842\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.1841\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 5s 50ms/step - loss: 0.1840\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 5s 46ms/step - loss: 0.1840\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 5s 47ms/step - loss: 0.1840\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 4s 44ms/step - loss: 0.1840\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 4s 44ms/step - loss: 0.1840\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 4s 44ms/step - loss: 0.1840\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 5s 46ms/step - loss: 0.1840\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(\n",
    "    [data_eda, data_temp],  # Input data\n",
    "    data_eda,  # Target data for both EDA and ECG\n",
    "    epochs=10,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6c4d099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_eda (InputLayer)         [(None, 40, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " input_temp (InputLayer)        [(None, 40, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " random_masking_layer_12 (Rando  (None, 40, 1)       0           ['input_eda[0][0]']              \n",
      " mMaskingLayer)                                                                                   \n",
      "                                                                                                  \n",
      " random_masking_layer_13 (Rando  (None, 40, 1)       0           ['input_temp[0][0]']             \n",
      " mMaskingLayer)                                                                                   \n",
      "                                                                                                  \n",
      " conv1d_84 (Conv1D)             (None, 40, 32)       128         ['random_masking_layer_12[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_87 (Conv1D)             (None, 40, 32)       128         ['random_masking_layer_13[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling1d_44 (MaxPooling1D  (None, 20, 32)      0           ['conv1d_84[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_46 (MaxPooling1D  (None, 20, 32)      0           ['conv1d_87[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_85 (Conv1D)             (None, 20, 64)       6208        ['max_pooling1d_44[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_88 (Conv1D)             (None, 20, 64)       6208        ['max_pooling1d_46[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling1d_45 (MaxPooling1D  (None, 10, 64)      0           ['conv1d_85[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_47 (MaxPooling1D  (None, 10, 64)      0           ['conv1d_88[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_86 (Conv1D)             (None, 10, 128)      24704       ['max_pooling1d_45[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_89 (Conv1D)             (None, 10, 128)      24704       ['max_pooling1d_47[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_17 (Flatten)           (None, 1280)         0           ['conv1d_86[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_18 (Flatten)           (None, 1280)         0           ['conv1d_89[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 2560)         0           ['flatten_17[0][0]',             \n",
      "                                                                  'flatten_18[0][0]']             \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 2560)         6556160     ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 5120)         13112320    ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 40, 128)      0           ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_90 (Conv1D)             (None, 40, 128)      49280       ['reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling1d_12 (UpSampling1D  (None, 80, 128)     0           ['conv1d_90[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_91 (Conv1D)             (None, 80, 64)       24640       ['up_sampling1d_12[0][0]']       \n",
      "                                                                                                  \n",
      " up_sampling1d_13 (UpSampling1D  (None, 160, 64)     0           ['conv1d_91[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 40, 64)       0           ['up_sampling1d_13[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_92 (Conv1D)             (None, 40, 1)        193         ['lambda_6[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 19,804,673\n",
      "Trainable params: 19,804,673\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e116757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d616d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ff07c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Dense, Flatten, concatenate\n",
    "\n",
    "def create_supervised_model(time_steps, num_classes):\n",
    "    # Create new input layers\n",
    "    input_eda = Input(shape=(time_steps, 1), name='input_eda')\n",
    "    input_temp = Input(shape=(time_steps, 1), name='input_temp')\n",
    "\n",
    "    # First branch - EDA\n",
    "    x_eda = Conv1D(32, 3, activation='relu', padding='same')(input_eda)\n",
    "    x_eda = MaxPooling1D(2, padding='same')(x_eda)\n",
    "    x_eda = Conv1D(64, 3, activation='relu', padding='same')(x_eda)\n",
    "    x_eda = MaxPooling1D(2, padding='same')(x_eda)\n",
    "    encoded_eda = Conv1D(128, 3, activation='relu', padding='same')(x_eda)\n",
    "\n",
    "    # Second branch - Temp\n",
    "    x_temp = Conv1D(32, 3, activation='relu', padding='same')(input_temp)\n",
    "    x_temp = MaxPooling1D(2, padding='same')(x_temp)\n",
    "    x_temp = Conv1D(64, 3, activation='relu', padding='same')(x_temp)\n",
    "    x_temp = MaxPooling1D(2, padding='same')(x_temp)\n",
    "    encoded_temp = Conv1D(128, 3, activation='relu', padding='same')(x_temp)\n",
    "\n",
    "    # Combine the outputs from the EDA and Temp encoders\n",
    "    combined = concatenate([encoded_eda, encoded_temp])\n",
    "\n",
    "    # Flatten and add dense layers for classification\n",
    "    x = Flatten()(combined)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    output = Dense(num_classes, activation='linear')(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=[input_eda, input_temp], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Define model parameters\n",
    "time_steps = 40  # Adjust to match the length of your time series data\n",
    "num_classes = 1  # Adjust based on your dataset\n",
    "\n",
    "# Create the model\n",
    "supervised_model = create_supervised_model(time_steps, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "# supervised_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "supervised_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "# Model summary\n",
    "# supervised_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "50de9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Dense, Flatten, concatenate\n",
    "\n",
    "def create_fine_tuning_model(pretrained_model, time_steps, num_classes):\n",
    "    # Create new input layers\n",
    "    input_eda = Input(shape=(time_steps, 1), name='new_input_eda')\n",
    "    input_temp = Input(shape=(time_steps, 1), name='new_input_temp')\n",
    "\n",
    "    # First branch - EDA\n",
    "    layer_eda_1 = Conv1D(32, 3, activation='relu', padding='same')\n",
    "    x_eda = layer_eda_1(input_eda)\n",
    "    layer_eda_1.set_weights(pretrained_model.get_layer(name='conv1d_84').get_weights())\n",
    "    x_eda = MaxPooling1D(2, padding='same')(x_eda)\n",
    "\n",
    "    layer_eda_2 = Conv1D(64, 3, activation='relu', padding='same')\n",
    "    x_eda = layer_eda_2(x_eda)\n",
    "    layer_eda_2.set_weights(pretrained_model.get_layer(name='conv1d_85').get_weights())  # Corrected layer name\n",
    "    x_eda = MaxPooling1D(2, padding='same')(x_eda)\n",
    "\n",
    "    layer_eda_3 = Conv1D(128, 3, activation='relu', padding='same')\n",
    "    x_eda = layer_eda_3(x_eda)\n",
    "    layer_eda_3.set_weights(pretrained_model.get_layer(name='conv1d_86').get_weights())  # Corrected layer name\n",
    "\n",
    "    # Second branch - Temp\n",
    "    layer_temp_1 = Conv1D(32, 3, activation='relu', padding='same')\n",
    "    x_temp = layer_temp_1(input_temp)\n",
    "    layer_temp_1.set_weights(pretrained_model.get_layer(name='conv1d_87').get_weights())\n",
    "    x_temp = MaxPooling1D(2, padding='same')(x_temp)\n",
    "\n",
    "    layer_temp_2 = Conv1D(64, 3, activation='relu', padding='same')\n",
    "    x_temp = layer_temp_2(x_temp)\n",
    "    layer_temp_2.set_weights(pretrained_model.get_layer(name='conv1d_88').get_weights())  # Corrected layer name\n",
    "    x_temp = MaxPooling1D(2, padding='same')(x_temp)\n",
    "\n",
    "    layer_temp_3 = Conv1D(128, 3, activation='relu', padding='same')\n",
    "    x_temp = layer_temp_3(x_temp)\n",
    "    layer_temp_3.set_weights(pretrained_model.get_layer(name='conv1d_89').get_weights())\n",
    "\n",
    "    # Combine the outputs from the EDA and Temp encoders\n",
    "    combined = concatenate([x_eda, x_temp])\n",
    "\n",
    "    # Flatten and add new trainable layers for fine-tuning\n",
    "    x = Flatten()(combined)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    output = Dense(num_classes, activation='linear')(x)\n",
    "\n",
    "    # Create the fine-tuning model\n",
    "    fine_tune_model = Model(inputs=[input_eda, input_temp], outputs=output)\n",
    "\n",
    "    # Optionally, freeze the layers from the pretrained model\n",
    "    for layer in fine_tune_model.layers[:-3]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return fine_tune_model\n",
    "\n",
    "time_steps =40\n",
    "\n",
    "# Load the pretrained autoencoder\n",
    "pretrained_autoencoder = tf.keras.models.load_model('model.h5', custom_objects={'RandomMaskingLayer': RandomMaskingLayer})\n",
    "\n",
    "# Number of classes for the fine-tuning task\n",
    "num_classes = 1\n",
    "\n",
    "# Create the fine-tuning model\n",
    "fine_tune_model = create_fine_tuning_model(pretrained_autoencoder, time_steps, num_classes)\n",
    "# fine_tune_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "fine_tune_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "829450c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "690108c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "aa4be627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(filtered_signal_data_for_label_2, filtered_signal_data_for_label_3, filtered_signal_data_for_label_4):\n",
    "    \n",
    "    return (\n",
    "        np.array([filtered_signal_data_for_label_2[i:i+segment_size] for i in range(0,len(filtered_signal_data_for_label_2) - segment_size + 1,overlap)]),\n",
    "        np.array([filtered_signal_data_for_label_3[i:i+segment_size] for i in range(0,len(filtered_signal_data_for_label_3) - segment_size + 1,overlap)]),\n",
    "        np.array([filtered_signal_data_for_label_4[i:i+segment_size] for i in range(0,len(filtered_signal_data_for_label_4) - segment_size + 1,overlap)]) \n",
    "    \n",
    "    )\n",
    "    \n",
    "    \n",
    "def build_data_with_forecasting(signal,window,output_length, overlap):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    start=0\n",
    "    while (True):\n",
    "        x1=signal[start:start+window]\n",
    "        output=signal[start+window:start+window+output_length] # 10 points\n",
    "        if (len(output)!=output_length):\n",
    "            break\n",
    "        X.append(x1)\n",
    "        y.append(output)\n",
    "        start=start+overlap\n",
    "    return X\n",
    "\n",
    "def process_signal(data,frequency, labels_chest,train_duration,output_length, overlap):\n",
    "    labels_wrist = []\n",
    "    for i in range(0, len(labels_chest), 700):\n",
    "        for _ in range(frequency):\n",
    "            labels_wrist.append(labels_chest[i])\n",
    "    labels_wrist = np.array(labels_wrist)\n",
    "    \n",
    "    filtered_indices_label_2 = np.where(labels_wrist == 2)  # 2= stress\n",
    "    filtered_indices_label_2= filtered_indices_label_2[0]\n",
    "    filtered_indices_label_3 = np.where(labels_wrist == 3) # 3 = amusement\n",
    "    filtered_indices_label_3= filtered_indices_label_3[0]\n",
    "    filtered_indices_label_4 = np.where(labels_wrist == 4) # 4 =\n",
    "    filtered_indices_label_4 = filtered_indices_label_4[0]\n",
    "    \n",
    "    filtered_indices_label_7 = np.where(labels_wrist == 7) # 4 =\n",
    "    filtered_indices_label_7 = filtered_indices_label_7[0]\n",
    "    \n",
    "    filtered_signal_data_for_label_2 = data[filtered_indices_label_2]\n",
    "    filtered_signal_data_for_label_3 = data[filtered_indices_label_3]\n",
    "    filtered_signal_data_for_label_4 = data[filtered_indices_label_4]\n",
    "    \n",
    "    filtered_signal_data_for_label_7 = data[filtered_indices_label_7]\n",
    "    \n",
    "#     data_label_2, data_label_3, data_label_4 = chunk_data(filtered_signal_data_for_label_2, filtered_signal_data_for_label_3, filtered_signal_data_for_label_4)\n",
    "    data_label_2 = build_data_with_forecasting(filtered_signal_data_for_label_2,train_duration*frequency,output_length, overlap)\n",
    "    data_label_3 = build_data_with_forecasting(filtered_signal_data_for_label_3,train_duration*frequency,output_length, overlap)\n",
    "    data_label_4 = build_data_with_forecasting(filtered_signal_data_for_label_4,train_duration*frequency,output_length, overlap)\n",
    "    \n",
    "    test_no_stress = build_data_with_forecasting(filtered_signal_data_for_label_7,train_duration*frequency,output_length, overlap)\n",
    "\n",
    "    \n",
    "    return data_label_2, data_label_3, data_label_4, test_no_stress\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def balance_data(data_label_2, data_label_3, data_label_4):\n",
    "    while True:\n",
    "        len_2, len_3, len_4 = len(data_label_2), len(data_label_3), len(data_label_4)\n",
    "        \n",
    "        if len_3 + len_4 > len_2:\n",
    "            # If combined length of data_label_3 and data_label_4 is greater, remove from them\n",
    "            if len(data_label_3) > len(data_label_4):\n",
    "                idx_to_remove = np.random.randint(len(data_label_3))\n",
    "                data_label_3 = np.delete(data_label_3, idx_to_remove, axis=0)\n",
    "            else:\n",
    "                idx_to_remove = np.random.randint(len(data_label_4))\n",
    "                data_label_4 = np.delete(data_label_4, idx_to_remove, axis=0)\n",
    "                \n",
    "        elif len_2 > len_3 + len_4:\n",
    "            # If length of data_label_2 is greater, remove from it\n",
    "            idx_to_remove = np.random.randint(len(data_label_2))\n",
    "            data_label_2 = np.delete(data_label_2, idx_to_remove, axis=0)\n",
    "            \n",
    "        else:\n",
    "            # If lengths are balanced, exit the loop\n",
    "            break\n",
    "            \n",
    "    return data_label_2, data_label_3, data_label_4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def make_data_for_pt(output_dir, X_train, X_test, y_train, y_test, X_val,y_val ):\n",
    "    dat_dict = dict()\n",
    "    dat_dict[\"samples\"] = torch.from_numpy(X_train)\n",
    "    dat_dict[\"labels\"] = torch.from_numpy(y_train)\n",
    "    torch.save(dat_dict, os.path.join(output_dir, \"train.pt\"))\n",
    "\n",
    "    dat_dict = dict()\n",
    "    dat_dict[\"samples\"] = torch.from_numpy(X_val)\n",
    "    dat_dict[\"labels\"] = torch.from_numpy(y_val)\n",
    "    torch.save(dat_dict, os.path.join(output_dir, \"val.pt\"))\n",
    "\n",
    "    dat_dict = dict()\n",
    "    dat_dict[\"samples\"] = torch.from_numpy(X_test)\n",
    "    dat_dict[\"labels\"] = torch.from_numpy(y_test)\n",
    "    torch.save(dat_dict, os.path.join(output_dir, \"test.pt\"))\n",
    "    \n",
    "def get_frequency(signal):\n",
    "    if signal==\"ACC\":\n",
    "        frequency= 32\n",
    "    elif signal==\"BVP\":\n",
    "        frequency= 64\n",
    "    else:\n",
    "        frequency= 4\n",
    "        \n",
    "    return frequency\n",
    "\n",
    "\n",
    "def training_data_based_on_data_points(n_samples_per_class,train_eda,train_temp,y_train,mse):\n",
    "    \n",
    "    if mse==True:\n",
    "\n",
    "        n_samples_per_class = int(n_samples_per_class/2)\n",
    "\n",
    "        # Separate the training set into classes\n",
    "        class_0_indices = np.where(y_train == 0)[0]\n",
    "        class_1_indices = np.where(y_train == 1)[0]\n",
    "\n",
    "        # Randomly choose 5 indices from each class\n",
    "    #     np.random.seed(42)  # for reproducibility\n",
    "        selected_class_0_indices = np.random.choice(class_0_indices, n_samples_per_class, replace=False)\n",
    "        selected_class_1_indices = np.random.choice(class_1_indices, n_samples_per_class, replace=False)\n",
    "\n",
    "        # Combine the indices\n",
    "        selected_indices = np.concatenate((selected_class_0_indices, selected_class_1_indices))\n",
    "\n",
    "        # Extract the corresponding data points and labels\n",
    "        selected_X_eda_train = train_eda[selected_indices]\n",
    "        selected_X_temp_train = train_temp[selected_indices]\n",
    "        selected_y_train = y_train[selected_indices]\n",
    "\n",
    "        return selected_X_eda_train,selected_X_temp_train, selected_y_train\n",
    "    else:\n",
    "        \n",
    "        n_samples_per_class = int(n_samples_per_class/2)\n",
    "\n",
    "        # Separate the training set into classes\n",
    "        class_0_indices = np.where(y_train == 0)[0]\n",
    "        class_1_indices = np.where(y_train == 0.25)[0]\n",
    "\n",
    "        # Randomly choose 5 indices from each class\n",
    "    #     np.random.seed(42)  # for reproducibility\n",
    "        selected_class_0_indices = np.random.choice(class_0_indices, n_samples_per_class, replace=False)\n",
    "        selected_class_1_indices = np.random.choice(class_1_indices, n_samples_per_class, replace=False)\n",
    "\n",
    "        # Combine the indices\n",
    "        selected_indices = np.concatenate((selected_class_0_indices, selected_class_1_indices))\n",
    "\n",
    "        # Extract the corresponding data points and labels\n",
    "        selected_X_eda_train = train_eda[selected_indices]\n",
    "        selected_X_temp_train = train_temp[selected_indices]\n",
    "        selected_y_train = y_train[selected_indices]\n",
    "\n",
    "        return selected_X_eda_train,selected_X_temp_train, selected_y_train\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "44af547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2540, 1) (2540, 1)\n",
      "(540, 1) (540, 1)\n",
      "(2000, 1) (2000, 1)\n",
      "Test Stress Eda Shape:  (191, 160, 1)\n",
      "Test NO STRESS temp Shape:  (25, 160, 1)\n",
      "Train Shape:  (3117, 160, 1) (3117, 160, 1) (3117,)\n",
      "Test Shape:  (216, 160, 1) (216, 160, 1) (216,)\n"
     ]
    }
   ],
   "source": [
    "# frequency=0\n",
    "train_duration =40\n",
    "# overlap=2\n",
    "subject=\"S4\"\n",
    "signal= \"TEMP\"\n",
    "root = \"../Wesad/Dataset/WESAD/untitled folder/\"\n",
    "path = root+subject+\".pkl\"\n",
    "\n",
    "\n",
    "\n",
    "if signal==\"ACC\":\n",
    "    frequency= 32\n",
    "elif signal==\"BVP\":\n",
    "    frequency= 64\n",
    "else:\n",
    "    frequency= 4\n",
    "\n",
    "segment_size = train_duration*frequency\n",
    "# frequency  = get_frequency(signal)\n",
    "    \n",
    "segment_size = train_duration*frequency\n",
    "\n",
    "if frequency==1:\n",
    "    overlap=frequency\n",
    "else:\n",
    "    overlap = int(0.5*frequency)\n",
    "    \n",
    "with open(path, 'rb') as file:\n",
    "    whole_signal = pickle.load(file, encoding='latin1')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_eda= whole_signal['signal']['wrist']['EDA']\n",
    "data_temp= whole_signal['signal']['wrist']['TEMP']\n",
    "\n",
    "\n",
    "labels_chest = whole_signal[\"label\"]\n",
    "\n",
    "labels_wrist = []\n",
    "for i in range(0, len(labels_chest), 700):\n",
    "    for _ in range(frequency):\n",
    "        labels_wrist.append(labels_chest[i])\n",
    "\n",
    "labels_wrist = np.array(labels_wrist)\n",
    "\n",
    "#     labels_wrist = whole_signal[\"label\"]\n",
    "\n",
    "\n",
    "filtered_indices_label_0 = np.where(labels_wrist == 0)  \n",
    "filtered_indices_label_0= filtered_indices_label_0[0]\n",
    "\n",
    "filtered_indices_label_1 = np.where(labels_wrist == 1)  \n",
    "filtered_indices_label_1= filtered_indices_label_1[0]\n",
    "\n",
    "\n",
    "filtered_indices_label_2 = np.where(labels_wrist == 2)  # 2= stress\n",
    "filtered_indices_label_2= filtered_indices_label_2[0]\n",
    "\n",
    "\n",
    "filtered_indices_label_3 = np.where(labels_wrist == 3) # 3 = amusement\n",
    "filtered_indices_label_3= filtered_indices_label_3[0]\n",
    "\n",
    "\n",
    "filtered_indices_label_4 = np.where(labels_wrist == 4) # 4 =\n",
    "filtered_indices_label_4 = filtered_indices_label_4[0]\n",
    "\n",
    "filtered_indices_label_5 = np.where(labels_wrist == 5)  \n",
    "filtered_indices_label_5= filtered_indices_label_5[0]\n",
    "\n",
    "filtered_indices_label_6 = np.where(labels_wrist == 6) \n",
    "filtered_indices_label_6= filtered_indices_label_6[0]\n",
    "\n",
    "filtered_indices_label_7 = np.where(labels_wrist == 7)  \n",
    "filtered_indices_label_7= filtered_indices_label_7[0]\n",
    "\n",
    "\n",
    "eda_data_for_label_0 = data_eda[filtered_indices_label_0]\n",
    "eda_data_for_label_1 = data_eda[filtered_indices_label_1]\n",
    "eda_data_for_label_2 = data_eda[filtered_indices_label_2]\n",
    "eda_data_for_label_3 = data_eda[filtered_indices_label_3]\n",
    "eda_data_for_label_4 = data_eda[filtered_indices_label_4]\n",
    "eda_data_for_label_5 = data_eda[filtered_indices_label_5]\n",
    "eda_data_for_label_6 = data_eda[filtered_indices_label_6]\n",
    "eda_data_for_label_7 = data_eda[filtered_indices_label_7]\n",
    "\n",
    "\n",
    "temp_data_for_label_0 = data_temp[filtered_indices_label_0]\n",
    "temp_data_for_label_1 = data_temp[filtered_indices_label_1]\n",
    "temp_data_for_label_2 = data_temp[filtered_indices_label_2]\n",
    "temp_data_for_label_3 = data_temp[filtered_indices_label_3]\n",
    "temp_data_for_label_4 = data_temp[filtered_indices_label_4]\n",
    "temp_data_for_label_5 = data_temp[filtered_indices_label_5]\n",
    "temp_data_for_label_6 = data_temp[filtered_indices_label_6]\n",
    "temp_data_for_label_7 = data_temp[filtered_indices_label_7]\n",
    "\n",
    "print(eda_data_for_label_2.shape,temp_data_for_label_2.shape)\n",
    "\n",
    "\n",
    "test_stress_eda = eda_data_for_label_2[-540:]\n",
    "test_stress_eda = np.array([test_stress_eda[i:i + segment_size] for i in range(0, len(test_stress_eda) - segment_size + 1, overlap)])\n",
    "test_stress_temp = temp_data_for_label_2[-540:]\n",
    "test_stress_temp = np.array([test_stress_temp[i:i + segment_size] for i in range(0, len(test_stress_temp) - segment_size + 1, overlap)])\n",
    "\n",
    "print(test_eda_label_2.shape, test_temp_label_2.shape)\n",
    "\n",
    "\n",
    "eda_data_for_label_2 = eda_data_for_label_2[:-540]\n",
    "temp_data_for_label_2 = temp_data_for_label_2[:-540]\n",
    "\n",
    "\n",
    "print(eda_data_for_label_2.shape,temp_data_for_label_2.shape)\n",
    "\n",
    "\n",
    "\n",
    "data_eda_label_0 = np.array([eda_data_for_label_0[i:i + segment_size] for i in range(0, len(eda_data_for_label_0) - segment_size + 1, overlap)])\n",
    "data_eda_label_1 = np.array([eda_data_for_label_1[i:i + segment_size] for i in range(0, len(eda_data_for_label_1) - segment_size + 1, overlap)])\n",
    "data_eda_label_2 = np.array([eda_data_for_label_2[i:i + segment_size] for i in range(0, len(eda_data_for_label_2) - segment_size + 1, overlap)])\n",
    "data_eda_label_3 = np.array([eda_data_for_label_3[i:i + segment_size] for i in range(0, len(eda_data_for_label_3) - segment_size + 1, overlap)])\n",
    "data_eda_label_4 = np.array([eda_data_for_label_4[i:i + segment_size] for i in range(0, len(eda_data_for_label_4) - segment_size + 1, overlap)])\n",
    "data_eda_label_5 = np.array([eda_data_for_label_5[i:i + segment_size] for i in range(0, len(eda_data_for_label_5) - segment_size + 1, overlap)])\n",
    "data_eda_label_6 = np.array([eda_data_for_label_6[i:i + segment_size] for i in range(0, len(eda_data_for_label_6) - segment_size + 1, overlap)])\n",
    "data_eda_label_7 = np.array([eda_data_for_label_7[i:i + segment_size] for i in range(0, len(eda_data_for_label_7) - segment_size + 1, overlap)])\n",
    "\n",
    "data_temp_label_0 = np.array([temp_data_for_label_0[i:i + segment_size] for i in range(0, len(temp_data_for_label_0) - segment_size + 1, overlap)])\n",
    "data_temp_label_1 = np.array([temp_data_for_label_1[i:i + segment_size] for i in range(0, len(temp_data_for_label_1) - segment_size + 1, overlap)])\n",
    "data_temp_label_2 = np.array([temp_data_for_label_2[i:i + segment_size] for i in range(0, len(temp_data_for_label_2) - segment_size + 1, overlap)])\n",
    "data_temp_label_3 = np.array([temp_data_for_label_3[i:i + segment_size] for i in range(0, len(temp_data_for_label_3) - segment_size + 1, overlap)])\n",
    "data_temp_label_4 = np.array([temp_data_for_label_4[i:i + segment_size] for i in range(0, len(temp_data_for_label_4) - segment_size + 1, overlap)])\n",
    "data_temp_label_5 = np.array([temp_data_for_label_5[i:i + segment_size] for i in range(0, len(temp_data_for_label_5) - segment_size + 1, overlap)])\n",
    "data_temp_label_6 = np.array([temp_data_for_label_6[i:i + segment_size] for i in range(0, len(temp_data_for_label_6) - segment_size + 1, overlap)])\n",
    "data_temp_label_7 = np.array([temp_data_for_label_7[i:i + segment_size] for i in range(0, len(temp_data_for_label_7) - segment_size + 1, overlap)])\n",
    "\n",
    "\n",
    "train_no_stress_eda= np.concatenate((data_eda_label_3,data_eda_label_4), axis=0)\n",
    "train_no_stress_temp= np.concatenate((data_temp_label_3,data_temp_label_4), axis=0)\n",
    "train_no_stress_labels = np.array([0]*len(train_no_stress_eda))\n",
    "\n",
    "\n",
    "train_stress_eda= data_eda_label_2.copy()\n",
    "train_stress_temp= data_temp_label_2.copy()\n",
    "train_stress_labels = np.array([1]*len(train_stress_eda))\n",
    "\n",
    "\n",
    "train_eda = np.concatenate((train_stress_eda,train_no_stress_eda ), axis=0)\n",
    "train_temp = np.concatenate((train_stress_temp,train_no_stress_temp ), axis=0)\n",
    "train_labels = np.concatenate((train_stress_labels,train_no_stress_labels ), axis=0)\n",
    "\n",
    "\n",
    "test_no_stress_eda = data_eda_label_7.copy()\n",
    "test_no_stress_temp = data_temp_label_7.copy()\n",
    "test_no_stress_labels = np.array([0]*len(test_no_stress_eda))\n",
    "\n",
    "print(\"Test Stress Eda Shape: \", test_stress_eda.shape)\n",
    "print(\"Test NO STRESS temp Shape: \", test_no_stress_eda.shape)\n",
    "\n",
    "\n",
    "\n",
    "test_eda = np.concatenate((test_stress_eda,test_no_stress_eda ), axis=0)\n",
    "test_temp = np.concatenate((test_stress_temp,test_no_stress_temp ), axis=0)\n",
    "test_stress_labels = np.array([1]*len(test_stress_eda))\n",
    "test_labels = np.concatenate((test_stress_labels,test_no_stress_labels ), axis=0)\n",
    "\n",
    "    \n",
    "print(\"Train Shape: \", train_eda.shape, train_temp.shape,train_labels.shape )\n",
    "print(\"Test Shape: \", test_eda.shape, test_temp.shape,test_labels.shape )\n",
    "    \n",
    "\n",
    "\n",
    "# # ###  For SUPERISED TRAINING #####\n",
    "# data_label_2_eda, data_label_3_eda, data_label_4_eda, test_no_stress_eda = process_signal(data_eda,frequency, labels_chest,train_duration,40,overlap)\n",
    "# data_label_2_eda, data_label_3_eda, data_label_4_eda = balance_data(data_label_2_eda, data_label_3_eda, data_label_4_eda)\n",
    "\n",
    "\n",
    "# data_label_2_temp, data_label_3_temp, data_label_4_temp, test_no_stress_temp = process_signal(data_temp,frequency, labels_chest,train_duration,40,overlap)\n",
    "# data_label_2_temp, data_label_3_temp, data_label_4_temp = balance_data(data_label_2_temp, data_label_3_temp, data_label_4_temp)\n",
    "\n",
    "\n",
    "\n",
    "# data_stress_eda = data_label_2_eda.copy()\n",
    "# X_test_stress_eda = np.array(data_stress_eda[-200:])\n",
    "# data_stress_eda = np.array(data_stress_eda[:-200]) # Updated data with  stress\n",
    "\n",
    "\n",
    "# data_stress_temp = data_label_2_temp.copy()\n",
    "# X_test_stress_temp = np.array(data_stress_temp[-200:])\n",
    "# data_stress_temp =  np.array(data_stress_temp[:-200]) # Updated data with  stress\n",
    "\n",
    "# train_label_stress = np.array([1]*len(data_stress_eda))\n",
    "# test_label_stress = np.array([1]*len(X_test_stress_eda))\n",
    "\n",
    "# ##### a=make no stress data\n",
    "\n",
    "\n",
    "# data_no_stress_eda = np.concatenate((data_label_3_eda, data_label_4_eda),axis=0)\n",
    "# # X_test_no_stress_eda = np.array(data_no_stress_eda[-200:])\n",
    "\n",
    "\n",
    "# X_test_no_stress_eda = test_no_stress_eda.copy()\n",
    "\n",
    "# data_no_stress_temp = np.concatenate((data_label_3_temp, data_label_4_temp),axis=0)\n",
    "# # X_test_no_stress_temp = np.array(data_no_stress_temp[-200:])\n",
    "\n",
    "\n",
    "# X_test_no_stress_temp = test_no_stress_temp.copy()\n",
    "\n",
    "# # data_no_stress_eda = data_no_stress_eda[:-200] # Updated data with NO stress\n",
    "# # data_no_stress_temp = data_no_stress_temp[:-200] # Updated data with NO stress\n",
    "\n",
    "# train_no_label_stress = np.array([0]*len(data_no_stress_eda))\n",
    "# test_label_no_stress = np.array([0]*len(X_test_no_stress_eda))\n",
    "\n",
    "# train_eda= np.concatenate((data_stress_eda,data_no_stress_eda),axis=0)\n",
    "# train_temp = np.concatenate((data_no_stress_eda,data_no_stress_temp),axis=0)\n",
    "# train_labels = np.concatenate((train_label_stress,train_no_label_stress),axis=0)\n",
    "\n",
    "# test_eda= np.concatenate((X_test_stress_eda,X_test_no_stress_eda),axis=0)\n",
    "# test_temp = np.concatenate((X_test_no_stress_eda,X_test_no_stress_temp),axis=0)\n",
    "# test_labels = np.concatenate((test_label_stress,test_label_no_stress),axis=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d936b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_size=40\n",
    "train_stress_eda =pd.read_csv(\"train_stress_eda.csv\",usecols=[0])\n",
    "train_stress_eda=train_stress_eda.values\n",
    "train_stress_eda= np.array([train_stress_eda[i:i + segment_size] for i in range(0, len(train_stress_eda) - segment_size + 1, overlap)])\n",
    "\n",
    "\n",
    "train_no_stress_eda =pd.read_csv(\"train_no_stress_eda.csv\",usecols=[0])\n",
    "train_no_stress_eda=train_no_stress_eda.values\n",
    "train_no_stress_eda= np.array([train_no_stress_eda[i:i + segment_size] for i in range(0, len(train_no_stress_eda) - segment_size + 1, overlap)])\n",
    "\n",
    "\n",
    "test_stress_eda =pd.read_csv(\"test_stress_eda.csv\",usecols=[0])\n",
    "test_stress_eda=test_stress_eda.values\n",
    "test_stress_eda= np.array([test_stress_eda[i:i + segment_size] for i in range(0, len(test_stress_eda) - segment_size + 1, overlap)])\n",
    "# test_stress_eda_labels = np.array([1]*len(test_stress_eda))\n",
    "\n",
    "test_no_stress_eda =pd.read_csv(\"test_no_stress_eda.csv\",usecols=[0])\n",
    "test_no_stress_eda=test_no_stress_eda.values\n",
    "test_no_stress_eda= np.array([test_no_stress_eda[i:i + segment_size] for i in range(0, len(test_no_stress_eda) - segment_size + 1, overlap)])\n",
    "# test_no_stress_eda_labels = np.array([0]*len(test_no_stress_eda))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e970b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stress_temp =pd.read_csv(\"train_stress_temp.csv\",usecols=[0])\n",
    "train_stress_temp=train_stress_temp.values\n",
    "train_stress_temp= np.array([train_stress_temp[i:i + segment_size] for i in range(0, len(train_stress_temp) - segment_size + 1, overlap)])\n",
    "\n",
    "\n",
    "train_no_stress_temp =pd.read_csv(\"train_no_stress_temp.csv\",usecols=[0])\n",
    "train_no_stress_temp=train_no_stress_temp.values\n",
    "train_no_stress_temp= np.array([train_no_stress_temp[i:i + segment_size] for i in range(0, len(train_no_stress_temp) - segment_size + 1, overlap)])\n",
    "# train_no_stress_labels = np.array([0]*len(train_no_stress_temp))\n",
    "\n",
    "\n",
    "test_stress_temp =pd.read_csv(\"test_stress_temp.csv\",usecols=[0])\n",
    "test_stress_temp=test_stress_temp.values\n",
    "test_stress_temp= np.array([test_stress_temp[i:i + segment_size] for i in range(0, len(test_stress_temp) - segment_size + 1, overlap)])\n",
    "# test_stress_temp_labels = np.array([1]*len(test_stress_temp))\n",
    "\n",
    "test_no_stress_temp =pd.read_csv(\"test_no_stress_temp.csv\",usecols=[0])\n",
    "test_no_stress_temp=test_no_stress_temp.values\n",
    "test_no_stress_temp= np.array([test_no_stress_temp[i:i + segment_size] for i in range(0, len(test_no_stress_temp) - segment_size + 1, overlap)])\n",
    "# test_no_stress_temp_labels = np.array([0]*len(test_no_stress_temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745699f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c632a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stress_labels = np.array([0.25]*len(train_stress_eda))\n",
    "train_no_stress_labels = np.array([0]*len(train_no_stress_eda))\n",
    "test_stress_labels = np.array([0.25]*len(test_stress_eda))\n",
    "test_no_stress_labels = np.array([0]*len(test_no_stress_eda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d0334ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eda = np.concatenate((train_stress_eda,train_no_stress_eda),axis=0)\n",
    "train_temp = np.concatenate((train_stress_temp,train_no_stress_temp),axis=0)\n",
    "train_labels= np.concatenate((train_stress_labels,train_no_stress_labels),axis=0)\n",
    "\n",
    "\n",
    "test_eda = np.concatenate((test_stress_eda,test_no_stress_eda),axis=0)\n",
    "test_temp = np.concatenate((test_stress_temp,test_no_stress_temp),axis=0)\n",
    "test_labels= np.concatenate((test_stress_labels,test_no_stress_labels),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e20ac612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3335, 40, 1)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "527842ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Point:  10\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0575 - mean_squared_error: 0.0575\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 9.2072e-04 - mean_squared_error: 9.2072e-04\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0246 - mean_squared_error: 0.0246\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0587 - mean_squared_error: 0.0587\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0619 - mean_squared_error: 0.0619\n",
      "SSL\n",
      "==============================\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 14:05:42.701245: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 0.9788 - mean_squared_error: 0.9788\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 17.2359 - mean_squared_error: 17.2359\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.5101 - mean_squared_error: 0.5101\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5193 - mean_squared_error: 1.5193\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6928 - mean_squared_error: 2.6928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 14:05:48.302204: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised Training\n",
      "==============================\n",
      "\n",
      "\n",
      "Data Point:  20\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0349 - mean_squared_error: 0.0349\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0280 - mean_squared_error: 0.0280\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0308 - mean_squared_error: 0.0308\n",
      "SSL\n",
      "==============================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.9114 - mean_squared_error: 1.9114\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4792 - mean_squared_error: 0.4792\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0260 - mean_squared_error: 0.0260\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5156 - mean_squared_error: 0.5156\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7878 - mean_squared_error: 0.7878\n",
      "Supervised Training\n",
      "==============================\n",
      "\n",
      "\n",
      "Data Point:  30\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0169 - mean_squared_error: 0.0169\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 9.9664e-04 - mean_squared_error: 9.9664e-04\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0150 - mean_squared_error: 0.0150\n",
      "SSL\n",
      "==============================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.5226 - mean_squared_error: 0.5226\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1698 - mean_squared_error: 0.1698\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0197 - mean_squared_error: 0.0197\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1628 - mean_squared_error: 0.1628\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1794 - mean_squared_error: 0.1794\n",
      "Supervised Training\n",
      "==============================\n",
      "\n",
      "\n",
      "Data Point:  40\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0154 - mean_squared_error: 0.0154\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "SSL\n",
      "==============================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0570 - mean_squared_error: 0.0570\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0170 - mean_squared_error: 0.0170\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0270 - mean_squared_error: 0.0270\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0360 - mean_squared_error: 0.0360\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
      "Supervised Training\n",
      "==============================\n",
      "\n",
      "\n",
      "Data Point:  50\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "SSL\n",
      "==============================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0211 - mean_squared_error: 0.0211\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0145 - mean_squared_error: 0.0145\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0136 - mean_squared_error: 0.0136\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0141 - mean_squared_error: 0.0141\n",
      "Supervised Training\n",
      "==============================\n",
      "\n",
      "\n",
      "Data Point:  60\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6360e-04 - mean_squared_error: 2.6360e-04\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "SSL\n",
      "==============================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0113 - mean_squared_error: 0.0113\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0139 - mean_squared_error: 0.0139\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0113 - mean_squared_error: 0.0113\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Supervised Training\n",
      "==============================\n",
      "\n",
      "\n",
      "Data Point:  70\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.4957e-04 - mean_squared_error: 6.4957e-04\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7423e-04 - mean_squared_error: 7.7423e-04\n",
      "SSL\n",
      "==============================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Supervised Training\n",
      "==============================\n",
      "\n",
      "\n",
      "Data Point:  80\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3501e-04 - mean_squared_error: 3.3501e-04\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8723e-04 - mean_squared_error: 3.8723e-04\n",
      "SSL\n",
      "==============================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Supervised Training\n",
      "==============================\n",
      "\n",
      "\n",
      "Data Point:  90\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 9.1722e-04 - mean_squared_error: 9.1722e-04\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5552e-04 - mean_squared_error: 3.5552e-04\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.7221e-04 - mean_squared_error: 2.7221e-04\n",
      "SSL\n",
      "==============================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 6.5137e-04 - mean_squared_error: 6.5137e-04\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Supervised Training\n",
      "==============================\n",
      "\n",
      "\n",
      "Data Point:  100\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.2607e-04 - mean_squared_error: 7.2607e-04\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 8.8818e-04 - mean_squared_error: 8.8818e-04\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.8600e-04 - mean_squared_error: 5.8600e-04\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7283e-04 - mean_squared_error: 2.7283e-04\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.3766e-04 - mean_squared_error: 3.3766e-04\n",
      "SSL\n",
      "==============================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 4s 4s/step - loss: 5.1105e-04 - mean_squared_error: 5.1105e-04\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.7327e-04 - mean_squared_error: 9.7327e-04\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Supervised Training\n",
      "==============================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_df=[]\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "epoch = 5\n",
    "ssl =[]\n",
    "non_ssl=[]\n",
    "for data_point in [10,20,30,40,50,60,70,80,90,100]:\n",
    "    print(\"Data Point: \", data_point)\n",
    "    for step in [1]:\n",
    "        new_X_train_eda,new_X_train_temp, new_y_train = training_data_based_on_data_points(data_point,train_eda,train_temp,train_labels,False)\n",
    "        history = fine_tune_model.fit(\n",
    "                    [new_X_train_eda, new_X_train_temp],  # Model inputs as a list\n",
    "                    new_y_train,                      # Training labels\n",
    "                    batch_size=100,                # Batch size (adjust as needed)\n",
    "                    epochs=epoch,                    # Number of epochs (adjust as needed)\n",
    "        # Fraction of data to use as validation\n",
    "                    verbose=1               # Verbosity mode\n",
    "                )\n",
    "#         predictions_finetune = fine_tune_model.predict([test_eda, test_temp],verbose=0)\n",
    "#         predicted_labels_finetune = np.argmax(predictions_finetune, axis=1)\n",
    "#         f1_finetune = f1_score(test_labels, predicted_labels_finetune, average='binary')  # Use 'binary' for binary classification\n",
    "        loss, mse_ssl = fine_tune_model.evaluate([test_eda, test_temp], test_labels, verbose=0)\n",
    "        rmse_ssl = abs(np.sqrt(mse_ssl))\n",
    "\n",
    "        df_ssl = pd.DataFrame({\n",
    "            'Subject':[subject],\n",
    "            'Data Points':[data_point],\n",
    "            'RMSE':[rmse_ssl]\n",
    "        })\n",
    "        ssl.append(df_ssl)\n",
    "        print(\"SSL\")\n",
    "#         print(confusion_matrix(test_labels, predicted_labels_finetune))\n",
    "        print(\"==============================\")\n",
    "        \n",
    "        history = supervised_model.fit(\n",
    "                        [new_X_train_eda, new_X_train_temp],  # Model inputs as a list\n",
    "                        new_y_train,                      # Training labels\n",
    "                        batch_size=1000,                # Batch size (adjust as needed)\n",
    "                        epochs=epoch,                    # Number of epochs (adjust as needed)\n",
    "                      # Fraction of data to use as validation\n",
    "                        verbose=1                # Verbosity mode\n",
    "                    )\n",
    "        \n",
    "#         predictions_supervised = supervised_model.predict([test_eda, test_temp],verbose=0)\n",
    "#         predicted_labels_supervised = np.argmax(predictions_supervised, axis=1)\n",
    "#         f1_supervised = f1_score(test_labels, predicted_labels_supervised, average='weighted')  # Use 'binary' for binary classification\n",
    "        \n",
    "        loss, mse_supervised = supervised_model.evaluate([test_eda, test_temp], test_labels, verbose=0)\n",
    "        rmse_supervised = abs(np.sqrt(mse_supervised))\n",
    "        df_non_ssl = pd.DataFrame({\n",
    "            'Subject':[subject],\n",
    "            'Data Points':[data_point],\n",
    "            'RMSE':[rmse_supervised]\n",
    "        })\n",
    "\n",
    "        non_ssl.append(df_non_ssl)\n",
    "        print(\"Supervised Training\")\n",
    "#         print(confusion_matrix(test_labels, predicted_labels_supervised))\n",
    "        print(\"==============================\")\n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "361daa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ssl= pd.concat(ssl)\n",
    "x_nonssl= pd.concat(non_ssl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c367098f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_ssl = x_ssl.copy()\n",
    "df_non_ssl = x_nonssl.copy()\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(df_ssl['Data Points'], df_ssl['RMSE'], label='SSL', marker='o')\n",
    "plt.plot(df_non_ssl['Data Points'], df_non_ssl['RMSE'], label='Non-SSL', marker='x')\n",
    "plt.xlabel('Data Points')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE Comparison between SSL and Non-SSL')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3f52017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 8.5509e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 7.7143e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 7.0696e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 6.5641e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 6.1638e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.0413e-05 - accuracy: 1.0000\n",
      "Test loss: 8.041272667469457e-05\n",
      "Test accuracy: 1.0\n",
      "13/13 [==============================] - 0s 5ms/step\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = fine_tune_model.fit(\n",
    "    [new_X_train_eda, new_X_train_temp],  # Model inputs as a list\n",
    "    new_y_train,                      # Training labels\n",
    "    batch_size=32,                # Batch size (adjust as needed)\n",
    "    epochs=epoch,                    # Number of epochs (adjust as needed)\n",
    "    validation_split=0.1,         # Fraction of data to use as validation\n",
    "    verbose=1                     # Verbosity mode\n",
    ")\n",
    "loss, accuracy = fine_tune_model.evaluate(\n",
    "    [test_eda, test_temp],  # Test inputs as a list\n",
    "    test_labels,                     # Test labels\n",
    "    verbose=1                   # Verbosity mode\n",
    ")\n",
    "\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)\n",
    "\n",
    "predictions = fine_tune_model.predict([test_eda, test_temp])\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "f1 = f1_score(test_labels, predicted_labels, average='weighted')  # Use 'binary' for binary classification\n",
    "\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b13e6cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 6s 4s/step - loss: 6.9074e-06 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.5068e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.0861e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.7881e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 9.2718e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 5.9605e-08 - accuracy: 1.0000\n",
      "Test loss: 5.9604641222676946e-08\n",
      "Test accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 20:22:16.163861: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 2s 92ms/step\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "history = supervised_model.fit(\n",
    "    [new_X_train_eda, new_X_train_temp],  # Model inputs as a list\n",
    "    new_y_train,                      # Training labels\n",
    "    batch_size=32,                # Batch size (adjust as needed)\n",
    "    epochs=epoch,                    # Number of epochs (adjust as needed)\n",
    "    validation_split=0.1,         # Fraction of data to use as validation\n",
    "    verbose=1                     # Verbosity mode\n",
    ")\n",
    "\n",
    "loss, accuracy = supervised_model.evaluate(\n",
    "    [test_eda, test_temp],  # Test inputs as a list\n",
    "    test_labels,                     # Test labels\n",
    "    verbose=1                   # Verbosity mode\n",
    ")\n",
    "\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)\n",
    "\n",
    "predictions = supervised_model.predict([test_eda, test_temp])\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "f1 = f1_score(test_labels, predicted_labels, average='weighted')  # Use 'binary' for binary classification\n",
    "\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "22f06478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 40, 1), (200, 40, 1), (200, 40, 1), (200, 40, 1))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4345c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stress = [0]*len(data_no_stress_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5c207bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbac3f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "mastersthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
